{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D74fm8bEPNld",
        "outputId": "b2977f89-f828-48f2-f3d1-0f80cef3e65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving...https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543372901157-3725350526242-001629-055-1224-2176-84-64.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543372901157-3725350526242-001629-055-1224-2176-84-64.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543372901157-3725350526242-001629-055-1224-2176-84-64.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543374882008-3725352526408-001649-138-1826-1500-72-56.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543374882008-3725352526408-001649-138-1826-1500-72-56.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1570543374882008-3725352526408-001649-138-1826-1500-72-56.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472012505862-10217420880920-000029-038-2396-558-68-116.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472012505862-10217420880920-000029-038-2396-558-68-116.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472012505862-10217420880920-000029-038-2396-558-68-116.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472120505648-10217528889899-001109-014-1434-1336-92-124.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472120505648-10217528889899-001109-014-1434-1336-92-124.jpeg?raw=True\n",
            "Image@ https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/aphanizomenon/training_data/SPC-EAWAG-0P5X-1589472120505648-10217528889899-001109-014-1434-1336-92-124.jpeg?raw=True\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "plankton_names = [\n",
        "        \"aphanizomenon\",\n",
        "        \"asplanchna\",\n",
        "        \"asterionella\",\n",
        "        \"bosmina\",\n",
        "        \"brachionus\",\n",
        "        \"ceratium\",\n",
        "        \"chaoborus\",\n",
        "        \"conochilus\",\n",
        "        \"copepod_skins\",\n",
        "        \"cyclops\",\n",
        "        \"daphnia\",\n",
        "        \"daphnia_skins\",\n",
        "        \"diaphanosoma\",\n",
        "        \"diatom_chain\",\n",
        "        \"dinobryon\",\n",
        "        \"dirt\",\n",
        "        \"eudiaptomus\",\n",
        "        \"filament\",\n",
        "        \"fish\",\n",
        "        \"fragilaria\",\n",
        "        \"hydra\",\n",
        "        \"kellicottia\",\n",
        "        \"keratella_cochlearis\",\n",
        "        \"keratella_quadrata\",\n",
        "        \"leptodora\",\n",
        "        \"maybe_cyano\",\n",
        "        \"nauplius\",\n",
        "        \"paradileptus\",\n",
        "        \"polyarthra\",\n",
        "        \"rotifers\",\n",
        "        \"synchaeta\",\n",
        "        \"trichocerca\",\n",
        "        \"unknown\",\n",
        "        \"unknown_plankton\",\n",
        "        \"uroglena\",\n",
        "    ]\n",
        "def retrieve_images(plankton):\n",
        "    repo_url_base = \"https://github.com/juleshenry/quantum-mnist/blob/main/data/zooplankton_0p5x/\"\n",
        "    photo_prefix = \"SPC-EAWAG-0P5X-\"\n",
        "    file_suffix = \".jpeg\"\n",
        "    raw_suffix = \"?raw=True\"\n",
        "    imgs = []\n",
        "    repo_data = repo_url_base + plankton + \"/training_data/\"\n",
        "    print(\"Retrieving...\" + repo_data)\n",
        "    r = requests.get(repo_data)\n",
        "    for o in str(r.content).split(photo_prefix)[1:13]:\n",
        "        img_url = (\n",
        "            repo_data\n",
        "            + photo_prefix\n",
        "            + o.split(file_suffix)[0]\n",
        "            + file_suffix\n",
        "            + raw_suffix\n",
        "        )\n",
        "        print(\"Image@\", img_url)\n",
        "        img = requests.get(img_url)\n",
        "        x = Image.open(io.BytesIO(img.content))\n",
        "        imgs.append(x)\n",
        "    return imgs\n",
        "\n",
        "dd = retrieve_images(plankton_names[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple helper to assign data\n",
        "def split_np_array_train_test(arr, train_test_ratio:float = 0.75):\n",
        "    split = int(round(len(arr)*train_test_ratio,0))\n",
        "    np.random.shuffle(arr)\n",
        "    return (arr[:split],arr[split:],)"
      ],
      "metadata": {
        "id": "T0JXTwIX0MJk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple helper to resize images bilinearly\n",
        "import math\n",
        "def bilinear_interpolation(image, y, x):\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "\n",
        "    x1 = max(min(math.floor(x), width - 1), 0)\n",
        "    y1 = max(min(math.floor(y), height - 1), 0)\n",
        "    x2 = max(min(math.ceil(x), width - 1), 0)\n",
        "    y2 = max(min(math.ceil(y), height - 1), 0)\n",
        "\n",
        "    a = float(image[y1, x1])\n",
        "    b = float(image[y2, x1])\n",
        "    c = float(image[y1, x2])\n",
        "    d = float(image[y2, x2])\n",
        "\n",
        "    dx = x - x1\n",
        "    dy = y - y1\n",
        "\n",
        "    new_pixel = a * (1 - dx) * (1 - dy)\n",
        "    new_pixel += b * dy * (1 - dx)\n",
        "    new_pixel += c * dx * (1 - dy)\n",
        "    new_pixel += d * dx * dy\n",
        "    return round(new_pixel)\n",
        "\n",
        "\n",
        "def bl_resize(image, new_height, new_width):\n",
        "    new_image = np.zeros((new_height, new_width), image.dtype)  # new_image = [[0 for _ in range(new_width)] for _ in range(new_height)]\n",
        "\n",
        "    orig_height = image.shape[0]\n",
        "    orig_width = image.shape[1]\n",
        "\n",
        "    # Compute center column and center row\n",
        "    x_orig_center = (orig_width-1) / 2\n",
        "    y_orig_center = (orig_height-1) / 2\n",
        "\n",
        "    # Compute center of resized image\n",
        "    x_scaled_center = (new_width-1) / 2\n",
        "    y_scaled_center = (new_height-1) / 2\n",
        "\n",
        "    # Compute the scale in both axes\n",
        "    scale_x = orig_width / new_width;\n",
        "    scale_y = orig_height / new_height;\n",
        "\n",
        "    for y in range(new_height):\n",
        "        for x in range(new_width):\n",
        "            x_ = (x - x_scaled_center) * scale_x + x_orig_center\n",
        "            y_ = (y - y_scaled_center) * scale_y + y_orig_center\n",
        "            new_image[y, x] = bilinear_interpolation(image, y_, x_)\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "1oCFcrf_0SRf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "qubit_dims = (4,4,)\n",
        "im1 = dd[0]\n",
        "def preprocess_images(image):\n",
        "    x = image.convert(\"L\") #grayscale\n",
        "    x = np.asarray(x) # numpy array\n",
        "    x = bl_resize(x, *qubit_dims) #resize\n",
        "    x = x / 255.0 #normalize\n",
        "    return x\n",
        "\n",
        "x_train, x_test = split_np_array_train_test(dd[p])\n",
        "    # y_train, y_test = np.array([p]*len(x_train)), np.array([p]*len(x_test))\n",
        "    # o = Image.fromarray(x_train[0])\n",
        "    # o.show()\n",
        "    # print(x_train_small[0])\n",
        "    # o = Image.fromarray(np.array(x_train_small[0]))\n",
        "    # o.show()\n",
        "    "
      ],
      "metadata": {
        "id": "h_sSSvvO0p_G"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "CeWqALQQsemK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the data\n",
        "## -In this notebook we will:\n",
        "## 1. Load the plankton data as graysale images \n",
        "## 2. Run round robin comparisons with classical 4x4 simple FFN\n",
        "## 3. Run round robin comparisons with quantum 4x4 example"
      ],
      "metadata": {
        "id": "oIpO-nEzPi1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}